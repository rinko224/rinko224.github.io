# Tiered Memory Management Beyond Hotness

## 1.摘要
分层内存系统通常依赖访问频率(hotness)来确定数据在不同层级的位置，即访问频率高的放在快内存，访问频率低的放在慢内存。但是实际上hotness对于性能并非总是最关键的。文章同时考虑了内存访问延迟和内存级并行性(MLP)，提出了一种新的指标-AOL(摊销的核外延迟，amortized offcore latency)，来更加准确地反映内存访问对性能的真实影响。
并且在此基础上，作者设计了两种分层机制：
- Soar：一种基于性能分析的分配机制，将对象根据它们的“性能贡献度”(performance contribution)分配到不同层级的内存中。
- Alto: 一种轻量级的页面(page)分配机制，用于取消对性能贡献不大的页面迁移。
  
在实验中，这两种策略比现在最先进的四种分层机制表现出更好的性能。

## 2.相关名词

- Memory-Level Parallelism(MLP):指同时并行发起多个内存访问请求的能力。例如对于MLP高的内存系统，CPU可以同时请求A,B,C,D四个内存地址，只要等最慢的一个回来就可以继续执行。
- Suboptimal data placement:
- Excessive migration overhead:
- CXL(Compute Express Link):一种高速串行协议，允许在计算机系统内部的不同组件之间进行快速、可靠的数据传输。其包含三个子协议：
  - CXL IO: 通过PCIe总线连接CPU和外部设备，这样CPU就可以与外部设备共享内存，并且可以直接访问外部设备的I/O资源。
  - CXL Cache: 允许CPU在本地缓存中保留最常用的数据，而把不常用的数据保存在外部设备中，减少内存访问时间，提升整体系统性能。
  - CXL Memory: 允许CPU将外部设备看作是扩展内存，从而可以存储更多的数据，使得即使发生了内存故障，CPU也仍可以通过外部设备继续允许，提高了系统的可靠性。
- TPP(Transparent Page Placement):透明页面分配机制，它采用热点页面优先分配的策略，将访问频率高的页面优先分配到快内存中。其的重要特点是对应用程序透明，应用程序不需要手动指定页面的存放，而又TPP在内核层自动决策。
- NBT(Linux NUMA-Balancing-Tiering):在NUMA架构下，内存的访问频率出现了本地和远程的区别，访问远程内存的延时会明显高于访问本地内存，这也就导致了如果任务运行的CPU和需要访问的数据不在同一节点上，访问延迟就会影响发挥CPU的性能。而NUMA-Balance的目的则是尽量让任务访问本节点内存。其实现分为两个小目标：1、如果任务访问的大部分内存不在本节点，那么就把任务迁移到该节点的CPU上运行；2、如果任务访问的大部分数据都在本节点，那么将其他节点上的数据迁移到该节点上。
- Nomad(Non-exclusive Memory Tiering):这是一种新的事物性页面迁移机制(TPM)，主要用于降低页面迁移的成本。其主要引入了两种创新的页面管理机制：
  - 异步页面迁移：Nomad采用异步的页面迁移机制，将页面迁移与用户程序的关键路径解耦，减少页面不可访问的持续时间。
  - 单向页面阴影机制：这一机制允许驻留在性能层中的页面子集在容量层中具有阴影副本。维护影子页的目的是为了帮助进行页面降级，如果性能层上的页未被修改，就可以直接通过页面重新映射实现快速高效的页面降级。为了追踪母版页是否被修改，Nomad会将母版页设置为只读，对页的写入会导致page fault。但是这里与linux中的页面管理系统又有所不同，其不采用写时复制(COW)的方式，而是引入了一个称为shadow page fault的过程，在发生page fault时，调用shadow page fault，根据shadow r/w位恢复待写页面的读写权限，并丢弃影子页面。
- Colloid()

## 3.现状
